{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predicting failing cable joints with a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "Our powergrid is an intricate network of cables/lines and stations that transport electricity from powerplants, solar parcs, wind parcs, etc. to e.g. your home. Within this network the cables are connected using cable joints (or 'Moffen' in Dutch). A range of joint types are used in our grid as these have improved over time. Older joints might experience failure due to a range of conditions. One of Alliander's main objectives is to have a reliable grid. Therefore, it is important to know which joint types are prone to failure in order to prevent power failures. \n",
    "\n",
    "Today, Alliander is going to ask you to come up with a way to predict cable joint failures using classification models. We know that joints fail due to large temperature variations and subsequently cause short circuits. The failure of cable joints is difficult to determine. However, we know that there is a relationship between a joint failure and the depth of a joint, the joint type, soil type and groundwater level. We also know that joint type is the most dominant factor to joint failures.\n",
    "\n",
    "Using the information supplied above and the supplied dataset containing information on the cable joints present in our grid, try to come up with classification models that predict the failure of cable joints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "1. [Import packages and load the data](#1)\n",
    "1. [Data Exploration](#2)\n",
    "1. [Preparation of the data](#3)\n",
    "1. [Analysis ](#4)\n",
    "1. [Split train- and testset](#5)\n",
    "1. [Model training](#6)\n",
    "1. [Model validation](#7)\n",
    "1. [Conclusion](#8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "\n",
    "## 1. Import packages and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set plotly as panda's default way of plotting\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data as a DataFrame\n",
    "df = pd.read_csv(\"data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "\n",
    "\n",
    "## 2. Data Exploration\n",
    "The first step of any Data Science project is to explore the dataset and familiarize yourself with the available variables.\n",
    "\n",
    "Here is an overview with a short description of each variable:\n",
    "| Variable | Description   |\n",
    "|------|------|\n",
    "| FAILURE  | Indicates whether the asset has failed. |\n",
    "| YEAR_CONSTRUCTION | The year that asset was installed in the network. |\n",
    "| YEAR_ACTIVE | The year in which the asset was first utilized. |\n",
    "| AGE | The age of the asset (determined in 2018). |\n",
    "| CABLE_COX1 | Cable type on installation side. |\n",
    "| CABLE_COX2 | Cable type on the network side. |\n",
    "| COX1==COX2 | Are cable 1 and 2 of the same type? |\n",
    "| CONSTRUCTION_ORIG | Original construction type of the cable-joint (as registrated in the database systems) |\n",
    "| CONSTRUCTION_EXP | Construction type estimated with a model |\n",
    "| CONSTRUCTION_COX | Construction type estimated with another model |\n",
    "| GROUND_TYPE | Type of ground/soil. \n",
    "| SUBSIDENCE  | Has the soil been subsided? |\n",
    "| DEWATERING_DEPTH_CM | The difference in cm between ground water level and surface level. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 First insights in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First view of the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Print the number of rows and columns.\n",
    "print('nrow:', df.shape[0])\n",
    "print('ncols:', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Show a short statistical summary (mean, standard deviation, etc) for the numeric values in the dataframe.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Show data types for each column.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2 Analyse the variable we try to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERICSE:\n",
    "# Make a count of the number of failures.\n",
    "df[\"FAILURE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3 Analyse categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Plot the columns that you want to inspect the values of.\n",
    "categorical_columns = [\n",
    "    \"CABLE_COX1\",\n",
    "    \"CABLE_COX2\",\n",
    "    \"CONSTRUCTION_ORIG\",\n",
    "    \"CONSTRUCTION_EXP\",\n",
    "    \"CONSTRUCTION_COX\",\n",
    "    \"GROUND_TYPE\"\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df.plot(\n",
    "        kind='hist',\n",
    "        x=col,\n",
    "        title=col\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.4 Analyse the distribution of the numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERICE:\n",
    "# Now make some figures to analyse the distribution of the values in the numerical columns. \n",
    "# Experiment with different chart types. For inspiration see: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "# Feel free to use explore an alternative library for producing figures if you feel like it.\n",
    "df.plot(\n",
    "    kind=\"hist\",\n",
    "    x=\"AGE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.plot(\n",
    "    kind=\"box\",\n",
    "    x=\"AGE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.5 Check for missing data\n",
    "\n",
    "When training a model the quality of your data can be a limiting factor.\n",
    "Therefore, it is wise to check the completeness of the column in your dataset early on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Provide insights (table or figure) in the percentage of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get insights in how many missing values (NULL or NANs) are in the dataset\n",
    "df_missing = pd.DataFrame(\n",
    "    data={\n",
    "        'NUM_MISSING': df.isna().sum(axis='rows'),\n",
    "        'NUM_TOTAL': len(df)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compute percentage missing\n",
    "df_missing['PCT_MISSING'] = df_missing['NUM_MISSING'] / df_missing['NUM_TOTAL']\n",
    "\n",
    "# Sort dataframe based on\n",
    "df_missing = df_missing.sort_values(by='PCT_MISSING', ascending=False)\n",
    "\n",
    "# Show the 'missing' dataframe\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "df_missing.plot(\n",
    "    kind='bar',\n",
    "    y='PCT_MISSING',\n",
    "    title=\"Missing Values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "\n",
    "\n",
    "## 3. Data Preparation\n",
    "In the data preparation step we want to re-structure our dataset to a format on which we can apply models.\n",
    "And also remove factors (such as outliers, missing values, incorrect data, etc.) that negatively impact the ability to train a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Based on your results in the exploration step, try to remove some absurd values (outliers) that might negatively impact a machine learning model.\n",
    "df = df[~(df[\"DEWATERING_DEPTH_CM\"] <= -30)]\n",
    "df = df[df[\"YEAR_CONSTRUCTION\"] > 1900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Fill missing values\n",
    "\n",
    "Not all models can handle handle missing values in input variables: NaN/None/etc.\n",
    "In that case you have to come up with a strategy on how to replace missing values if you want to be able to use all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Fill in (or remove) the missing values in numeric columns. A good strategy might be to fill the missing with the statistical average.\n",
    "df = df.fillna(df.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Apply one-hot-encoding on categorical variables\n",
    "Most models expect categorical variables to be one-hot encoded.\n",
    "See for more information: https://en.wikipedia.org/wiki/One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Find all the categorical variables and one-hot-encode them. \n",
    "# Hint: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "categorical_columns = [\n",
    "    \"CABLE_COX1\",\n",
    "    \"CABLE_COX2\",\n",
    "    \"CONSTRUCTION_ORIG\",\n",
    "    \"CONSTRUCTION_EXP\",\n",
    "    \"CONSTRUCTION_COX\",\n",
    "    \"GROUND_TYPE\"\n",
    "]\n",
    "\n",
    "df_prepped = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Check the prepped dataframe\n",
    "df_prepped.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"4\"></a> \n",
    "\n",
    "\n",
    "## 4. Analyse\n",
    "\n",
    "So far we have prepped the dataset and analysed the distributions of the variables.\n",
    "Before we start to train some models, it is a good idea to analyse the different relationships between the variables. \n",
    "Most importantly, how they relate to the failure of cable joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE: \n",
    "# Try make some useful figures to investigate the relationships between age-related variables and the amount of failures.\n",
    "df_prepped.plot(\n",
    "    kind=\"hist\",\n",
    "    x=\"AGE\",\n",
    "    color=\"FAILURE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Now try to find a way to visualise the relationships between the categorical variables and the failures of cable joints.\n",
    "\n",
    "columns = [\n",
    "    \"COX1==COX2\",\n",
    "    \"SUBSIDENCE\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(20, 140))\n",
    "for col in columns:\n",
    "    plt.figure()\n",
    "    sns.barplot(\n",
    "        x=df_prepped[col], \n",
    "        y=df_prepped[\"FAILURE\"], \n",
    "        palette='Blues'\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE: \n",
    "# Compute a correlation matrix for all the variables in the dataset. Select subsets to have clear overview, everything in one plot becomes quite unreadable.\n",
    "# What variables seem to be (strongly) correlated with \"FAILURE\" and with each other? Can you explain the relationships that you have found? And do they make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the columns here\n",
    "columns = ['FAILURE'] + df_prepped.columns[2:20].to_list()\n",
    "\n",
    "# Compute correlation matrix\n",
    "corrmat = df_prepped[columns].corr().round(2)\n",
    "\n",
    "# Correlation matrix figure (with seaborn)\n",
    "sns.set(rc={'figure.figsize':(16, 16)})\n",
    "sns.heatmap(corrmat, vmax=.8, square=True, annot=True, cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "\n",
    "\n",
    "## 5. Split train- and testset\n",
    "In order to validate how good you machine learning model is able to predict failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE: \n",
    "# Split the dataset into two dataframes one for training and the other for testing.\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df_prepped, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> \n",
    "## 6. Model training\n",
    "In this step we will train 3 different classification models.\n",
    "You can use [Model Validation](#7) to evaluate the performance of the models.\n",
    "Try to train and validate your models one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this dictionary we will save the trained models\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we define our predictive variable\n",
    "y_var = \"FAILURE\"\n",
    "y_train = df_train[y_var]\n",
    "y_test = df_test[y_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"6a\"></a> \n",
    "## 6.1 Decision Tree\n",
    "\n",
    "For more information see: https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "For the documentation of the sklearn implementation see: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Fit a Decision Tree model with the code below and experiment with different combinations of input variables \n",
    "# and hyperparameters, and investigate how they impact the results in the validation module below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the input variables for the model\n",
    "x_vars = [col for col in df_train.columns if col != y_var]\n",
    "\n",
    "x_train = df_train.loc[:, x_vars]\n",
    "x_test = df_test.loc[:, x_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "models[\"decision_tree\"] = sklearn.tree.DecisionTreeClassifier(\n",
    "    max_depth=16,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=2\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"6b\"></a> \n",
    "## 6.2 Random Forest \n",
    "\n",
    "For more information see: https://en.wikipedia.org/wiki/Random_forest\n",
    "\n",
    "For the documentation of the sklearn implementation see: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Fit a Random Forest model with the code below and experiment with different combinations of input variables \n",
    "# and hyperparameters, and investigate how they impact the results in the validation module below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the input variables for the model\n",
    "x_vars = [col for col in df_train.columns if col != y_var]\n",
    "\n",
    "x_train = df_train.loc[:, x_vars]\n",
    "x_test = df_test.loc[:, x_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models[\"random_forest\"] = sklearn.ensemble.RandomForestClassifier(\n",
    "    # Number of trees\n",
    "    n_estimators=100,\n",
    "    # Max depth of a tree\n",
    "    max_depth=16,\n",
    "    \n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"6v\"></a> \n",
    "## 6.3 XGBoost\n",
    "For more information see: https://en.wikipedia.org/wiki/XGBoost\n",
    "\n",
    "For more information of the xgb implementation see: https://xgboost.readthedocs.io/en/stable/python/python_api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Fit a XGBoost model with the code below and experiment with different combinations of input variables \n",
    "# and hyperparameters, and investigate how they impact the results in the validation module below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the input variables for the model\n",
    "x_vars = [col for col in df_train.columns if col != y_var]\n",
    "\n",
    "x_train = df_train.loc[:, x_vars]\n",
    "x_test = df_test.loc[:, x_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models[\"xgboost\"] = xgb.XGBClassifier(\n",
    "    random_state=42\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> \n",
    "## 7. Model Validation\n",
    "Now that we have trained a single or multiple models, we want to know how good it can predict the failure of cable joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List fitted models\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We select the model we want to evaluate here\n",
    "clf = models[\"decision_tree\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.1 Prediction on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Apply your model on the test-set and obtain two arrays:\n",
    "# - Class predictions, that indicate what class the model predicts (True for failure, False for non-failure).\n",
    "# - Class probabilities, that describe how certain the model is for each class (failure/non-failure).\n",
    "# Hint: use help(clf) to see what functions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on the test set (True/False for Failure/Non-failure)\n",
    "y_test_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict probabilities as well\n",
    "y_test_pred_proba = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Make a confusion matrix of the labels predicted by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = sklearn.metrics.confusion_matrix(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_test_pred\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cm).plot(\n",
    "    title=\"Confusion Matrix\",\n",
    "    kind=\"imshow\",\n",
    "    x=[\"Negative\", \"Positive\"],\n",
    "    y=[\"Negative\", \"Positive\"],\n",
    "    labels={\n",
    "        \"x\": \"Actual Values\",\n",
    "        \"y\": \"Predicted Values\"\n",
    "    },\n",
    "    text_auto=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Compute the accuracy of your model on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_score = sklearn.metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.4 F1 score and PR curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Compute the precision, recall and F1-score on the test predictions.\n",
    "# What do these values tell you? Also try to make a precision/recall curve to illustrade the trade-off between the the two for different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# F1 score\n",
    "f1_score = sklearn.metrics.f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"f1-score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute Precision and Recall curve\n",
    "precision, recall, _ = sklearn.metrics.precision_recall_curve(y_test,  y_test_pred_proba[:, 1])\n",
    "\n",
    "# Visualize curve\n",
    "(\n",
    "    pd.DataFrame({'Precision': precision, 'Recall': recall})\n",
    "    .plot(\n",
    "        title='PR Curve',\n",
    "        x='Recall', \n",
    "        y='Precision', \n",
    "        width=600, \n",
    "        height=600\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.5 AUC score and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Now compute an ROC curve and AUC score and interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve\n",
    "fpr, tpr, t = sklearn.metrics.roc_curve(y_test, y_test_pred_proba[:, 1])\n",
    "\n",
    "# Visualize ROC curve\n",
    "(\n",
    "    pd.DataFrame({'True Positive Rate': tpr, 'False Positive Rate': fpr})\n",
    "    .plot(\n",
    "        title='ROC Curve',\n",
    "        x='False Positive Rate', \n",
    "        y='True Positive Rate', \n",
    "        width=600, \n",
    "        height=600\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc_score = sklearn.metrics.auc(fpr, tpr)\n",
    "print(\"AUC score:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.6 Optimal Cut-off point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# The default threshold value that is applied on the predicted probabilty is often set at 0.5. \n",
    "# As you have seen with the PR and ROC curves, this threshold can be raised or lowered to prefer False Positives or False Negatives.\n",
    "# Now imagine that the following business costs are implied if we would apply your model:\n",
    "cost_tp = 50\n",
    "cost_tn = 0\n",
    "cost_fp = 50\n",
    "cost_fn = 100\n",
    "\n",
    "# Can you find the optimal threshold value for your model that minimizes the total cost of your predictions on the test-set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold_costs = []\n",
    "for threshold in np.linspace(0, 1, 100):\n",
    "    # Apply threshold\n",
    "    _y_test_pred = y_test_pred_proba[:, 1] > threshold\n",
    "    \n",
    "    # Compute amount of TP, TN, FP and FN\n",
    "    _cm = sklearn.metrics.confusion_matrix(_y_test_pred, y_test)\n",
    "    tn = _cm[0][0]\n",
    "    fn = _cm[0][1]\n",
    "    fp = _cm[1][0]\n",
    "    tp = _cm[1][1]\n",
    "    \n",
    "    # Compute costs\n",
    "    total_cost = tp * cost_tp + tn * cost_tn + fp * cost_fp + fn * cost_fn\n",
    "    \n",
    "    threshold_costs.append({'threshold': threshold, 'total_cost': total_cost})\n",
    "    \n",
    "df_threshold_costs = pd.DataFrame(threshold_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_threshold_costs.plot(\n",
    "    x='threshold',\n",
    "    y='total_cost'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute optimal threshold\n",
    "df_threshold_costs.iloc[df_threshold_costs['total_cost'].argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 7.7 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# Could you obtain the most important features in your model?\n",
    "# Is this in line with the observations you made in the data analysis step?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "df_feature_importances = (\n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"FEATURE\": clf.feature_names_in_,\n",
    "            \"IMPORTANCE\": clf.feature_importances_\n",
    "        }\n",
    "    )\n",
    "    .sort_values(\n",
    "        by=\"IMPORTANCE\", \n",
    "        ignore_index=True,\n",
    "        ascending=False\n",
    "    )\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "df_feature_importances.plot(\n",
    "    title=\"Feature Importances (Top 10)\",\n",
    "    kind=\"bar\", \n",
    "    x=\"IMPORTANCE\", \n",
    "    y=\"FEATURE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> \n",
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imagine that you can inspect or replace 200 cable joints (in the test-set). Which ones would you choose? \n",
    "# How many failures would you miss and how many replacements were unnecessary?\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Can you explain why some models seem to be able to predict failures better based on this dataset than others?\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
